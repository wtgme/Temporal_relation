{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from lmformatenforcer import JsonSchemaParser\n",
    "from pydantic import BaseModel\n",
    "import re, json, os\n",
    "from typing import Optional, Type, TypeVar, List, Dict, Any\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris is a city rich in history, culture, and art. Here are some must-see attractions and experiences you should consider during your visit:\n",
      "\n",
      "### Iconic Landmarks\n",
      "1. **Eiffel Tower**: No trip to Paris is complete without a visit to this iconic structure. You can take an elevator ride to the top for stunning views of the city.\n",
      "  \n",
      "2. **Louvre Museum**: Home to thousands of works of art, including the Mona Lisa and the Venus de Milo, the Louvre is a must-visit for art lovers.\n",
      "\n",
      "3. **Notre-Dame Cathedral**: Despite the ongoing restoration, the façade and surrounding areas are still worth a visit. Explore the nearby Île de la Cité and Sainte-Chapelle with its stunning stained glass.\n",
      "\n",
      "4. **Arc de Triomphe and Champs-Élysées**: Climb to the top of the Arc for panoramic views, and stroll down the famous avenue for shopping and dining.\n",
      "\n",
      "5. **Montmartre and Sacré-Cœur Basilica**: Explore the charming streets of Montmartre, visit the famous basilica, and enjoy breathtaking views of the city from its steps.\n",
      "\n",
      "### Cultural Experiences\n",
      "6. **Musee d'Orsay**: Located in a former railway station, this museum houses a vast collection of Impressionist and Post-Impressionist masterpieces.\n",
      "\n",
      "7. **Palace of Versailles**: Take a day trip to this opulent palace, known for its magnificent gardens and historical significance.\n",
      "\n",
      "8. **Seine River Cruise**: Enjoy a scenic boat ride along the Seine to see many of the city's landmarks from the water.\n",
      "\n",
      "### Neighborhoods to Explore\n",
      "9. **Le Marais**: A trendy neighborhood with cobblestone streets, boutiques, galleries, and great cafés. Don’t miss the Place des Vosges.\n",
      "\n",
      "10. **Latin Quarter**: Home to the Sorbonne and vibrant student life, this area has winding streets, bookstores, and plenty of restaurants.\n",
      "\n",
      "11. **Saint-Germain-des-Prés**: Known for its chic cafés, galleries, and boutiques, it's a great place for a leisurely afternoon.\n",
      "\n",
      "### Parks and Gardens\n",
      "12. **Luxembourg Gardens**: Beautifully manicured gardens perfect for a stroll or a picnic.\n",
      "\n",
      "13. **Tuileries Garden**: Located between the Louvre and Place de la Concorde, it's an ideal place to relax after visiting the museum.\n",
      "\n",
      "### Additional Suggestions\n",
      "14. **Get a Taste of Paris**: Try local cuisine at bistros or explore food markets like Marché des Enfants Rouges.\n",
      "\n",
      "15. **Visit a Cabaret**: Experience the Moulin Rouge or other cabarets for a unique night out.\n",
      "\n",
      "16. **Explore the Catacombs**: For something different, visit the underground ossuary that holds the remains of millions of Parisians.\n",
      "\n",
      "17. **Attend a Show at the Opéra**: Check the schedule for performances at Palais Garnier, a stunning opera house.\n",
      "\n",
      "### Tips\n",
      "- **Public Transport**: Utilize the Paris Métro for efficient travel around the city.\n",
      "- **Walking**: Many attractions are within walking distance of each other, so don't hesitate to explore on foot.\n",
      "\n",
      "Make sure to check the opening hours and any ticket requirements in advance, especially for popular attractions! Enjoy your trip to Paris!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "endpoint = \"https://twgmm-m9bsqfti-eastus2.openai.azure.com/\"\n",
    "model_name = \"gpt-4o-mini\"\n",
    "deployment = \"gpt-4o-mini\"\n",
    "\n",
    "subscription_key = \"9T33Ya79QaudQQABh7ZGjDL92cGHyFKLMIzwvchABHnYnCNDeLfgJQQJ99BDACHYHv6XJ3w3AAAAACOGjjRw\"\n",
    "api_version = \"2024-12-01-preview\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"I am going to Paris, what should I see?\",\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=4096,\n",
    "    temperature=1.0,\n",
    "    top_p=1.0,\n",
    "    model=deployment\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify OpenAI's API key and API base to use vLLM's API server.\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://host.docker.internal:8000/v1\"\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "model = 'Qwen/QwQ-32B-AWQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reasoning_content: Okay, so I need to figure out whether 9.11 is greater than 9.8 or not. Hmm, let's see. Both numbers start with 9, so the whole number part is the same. That means I have to look at the decimal parts to compare them. \n",
      "\n",
      "First, I remember that when comparing decimals, you start from the first digit after the decimal point. So, let's break them down. \n",
      "\n",
      "For 9.11, the digits after the decimal are 1 and 1. So, the tenths place is 1 and the hundredths place is 1. \n",
      "\n",
      "For 9.8, the digits after the decimal are 8 and then... well, there's nothing after that. So, it's just 8 in the tenths place and 0 in the hundredths place, right? Because 9.8 is the same as 9.80. \n",
      "\n",
      "So, comparing the tenths place first: 9.11 has 1 in the tenths, and 9.8 has 8 in the tenths. Since 8 is greater than 1, that would mean that 9.8 is actually larger than 9.11. Wait, but hold on, that seems counterintuitive because 11 is more than 8, but maybe I'm mixing up the places. \n",
      "\n",
      "Let me think again. Tenths are the first decimal digit. So in 9.11, the first decimal digit is 1, which is less than 8 in 9.8. Therefore, even though the second decimal digit in 9.11 is another 1, the tenths place is more important. Since 8 is bigger than 1, 9.8 is greater. \n",
      "\n",
      "But why did I think maybe 9.11 is bigger? Maybe because 11 is a two-digit number and 8 is single-digit? But in decimals, each position is a fraction. The tenths are worth more than the hundredths. So even if you have two digits in the decimal part, each subsequent digit is a smaller fraction. \n",
      "\n",
      "Let me verify this with another example. If I have 0.5 and 0.49, which is bigger? Well, 0.5 is the same as 0.50, so comparing to 0.49, the tenths place is 5 vs. 4, so 0.5 is bigger. Even though 49 is less than 50, the tenths place is the key. So same here. \n",
      "\n",
      "Therefore, in 9.11 vs. 9.8, since the tenths place of 9.8 is 8 versus 1 in 9.11, 9.8 is definitely larger. \n",
      "\n",
      "Wait, but maybe I made a mistake in reading the numbers. Let me check again. The problem says 9.11 and 9.8. Is there a possibility that 9.11 is 9 and 11 hundredths, whereas 9.8 is 9 and 8 tenths? Yes, exactly. \n",
      "\n",
      "So 9.8 is equal to 9 + 0.8, while 9.11 is 9 + 0.11. Since 0.8 is more than 0.11, the total is higher for 9.8. \n",
      "\n",
      "Alternatively, to make it clearer, I can convert both numbers to the same number of decimal places. \n",
      "\n",
      "9.8 can be written as 9.80. \n",
      "\n",
      "Then, comparing 9.11 and 9.80:\n",
      "\n",
      "- The units digit: both 9.\n",
      "- Tenths: 1 vs. 8. 8 is larger, so 9.80 is larger.\n",
      "- Hundredths: 1 vs. 0. But since the tenths already decided it, the hundredths don't matter.\n",
      "\n",
      "Therefore, 9.8 is greater than 9.11. \n",
      "\n",
      "I think that's solid. Maybe another way to see it is to subtract them. Let's subtract 9.11 from 9.8:\n",
      "\n",
      "9.8 - 9.11 = ?\n",
      "\n",
      "First, write both numbers aligned by decimal:\n",
      "\n",
      " 9.80\n",
      "-9.11\n",
      "-------\n",
      " 0.69\n",
      "\n",
      "So the result is 0.69, which is positive, meaning 9.8 is larger by 0.69. \n",
      "\n",
      "Alternatively, subtract the other way: 9.11 - 9.8 would be negative, confirming the same.\n",
      "\n",
      "Alternatively, convert them to fractions. \n",
      "\n",
      "9.11 is 911/100.\n",
      "\n",
      "9.8 is 98/10, which is 980/100.\n",
      "\n",
      "So comparing 911/100 and 980/100. Since they have the same denominator, just compare numerators: 911 vs. 980. 980 is bigger, so 9.8 is bigger.\n",
      "\n",
      "Yes, that's another way to confirm. \n",
      "\n",
      "I think I've verified it multiple ways. Tenths place comparison, converting to same decimal places, subtraction, and fractions. All point to 9.8 being greater than 9.11. \n",
      "\n",
      "So the answer is 9.8 is greater than 9.11. \n",
      "\n",
      "Wait, but hold on, the question is phrased as \"which is greater? 9.11 and 9.8\". So the user is asking which one is larger between the two. So the answer is 9.8. \n",
      "\n",
      "Therefore, I need to present that clearly. \n",
      "\n",
      "I think I might have overcomplicated it, but better safe than sorry. Let me recap once more:\n",
      "\n",
      "- Both numbers start with 9, so same whole number.\n",
      "- Compare first decimal digit: 1 vs. 8. 8 is larger, so 9.8 is bigger.\n",
      "- The rest of the digits don't matter once the first differing digit is found.\n",
      "\n",
      "Yep, that's solid. So the conclusion is correct.\n",
      "\n",
      "content: \n",
      "\n",
      "The number 9.8 is greater than 9.11. \n",
      "\n",
      "**Step-by-Step Explanation:**\n",
      "\n",
      "1. **Compare the whole numbers:** Both 9.11 and 9.8 have the same whole number part, which is 9. Therefore, we need to look at the decimal parts to determine which is larger.\n",
      "\n",
      "2. **Align the decimal places:** Write both numbers with the same number of decimal places for clarity:\n",
      "   - 9.11 remains as is (two decimal places).\n",
      "   - 9.8 can be written as 9.80 (two decimal places).\n",
      "\n",
      "3. **Compare the tenths place (first decimal digit):**\n",
      "   - 9.11 has **1** in the tenths place.\n",
      "   - 9.80 has **8** in the tenths place.\n",
      "   \n",
      "   Since 8 > 1, 9.80 (and thus 9.8) is already larger than 9.11 at this point.\n",
      "\n",
      "4. **Verification (optional):**\n",
      "   - Subtract 9.11 from 9.8:  \n",
      "     \\(9.8 - 9.11 = 0.69\\) (positive result confirms 9.8 is larger).\n",
      "   - Convert to fractions:  \n",
      "     \\(9.11 = \\frac{911}{100}\\), \\(9.8 = \\frac{980}{100}\\).  \n",
      "     Since \\(980 > 911\\), \\(9.8\\) is greater.\n",
      "\n",
      "**Answer:** 9.8 is greater than 9.11.\n"
     ]
    }
   ],
   "source": [
    "# Round 1\n",
    "messages = [{\"role\": \"user\", \"content\": \"9.11 and 9.8, which is greater?\"}]\n",
    "# For granite, add: `extra_body={\"chat_template_kwargs\": {\"thinking\": True}}`\n",
    "response = client.chat.completions.create(model=model, messages=messages)\n",
    "\n",
    "reasoning_content = response.choices[0].message.reasoning_content\n",
    "content = response.choices[0].message.content\n",
    "\n",
    "print(\"reasoning_content:\", reasoning_content)\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat response: Okay, let's tackle this query. The user wants me to extract clinical problems, tests, and treatments from the provided medical text and estimate the timing of each event. The admission and discharge dates are given as 09/29/1993 to 10/04/1993. \n",
      "\n",
      "First, I need to read through the entire text carefully. The HISTORY OF PRESENT ILLNESS section mentions the patient has left upper quadrant pain, nausea, vomiting, which have been ongoing, getting worse over the past month. Also, there's a mention of HIV positive since 1991. The HOSPITAL COURSE describes what happened during the hospital stay, including procedures and treatments.\n",
      "\n",
      "Starting with PROBLEMs. The main issues here are the left upper quadrant pain, nausea/vomiting, HIV infection, weight loss, and the abscesses in her legs. The abscess in the left lower extremity from 1991 and new ones in the left calf and right quadriceps. Also, failure to thrive and weight loss are noted. These should be listed as problems with their respective dates. The HIV diagnosis was in 1991, so that's separate. The current issues include the abscesses which were reasons for the current admission.\n",
      "\n",
      "Next, TESTS. The CT scan in 10/92 showed liver findings. Then during the current hospital stay, the esophagogastroduodenoscopy on 9/26 (but since admission is 9/29, maybe that was just before admission?), and the follow-up CT scan during the hospital stay. Also cultures were done when admitted, and the CT scan on 10/2. Wait, the debridement was on 10/2/93, so the CT might be part of that. Need to check exact dates.\n",
      "\n",
      "TREATMENTS: Percocet on the third day (since admission is 9/29, the third day would be 10/2?), but the patient was admitted on the 29th. Let me count days. From 9/29 to 9/30 is day 1, 10/1 day 2, 10/2 day 3. Yes, so the third hospital day is 10/2. The Percocet was given on that day. Then the debridement was on 10/2, so that's same day as the Percocet. The IV ceftriaxone was started empirically then, changed to oral doxycycline on discharge day (10/04). The social services are part of the admission reason but not a treatment per se. Also, the previous DDI (maybe didanosine?) caused pancytopenia, so she wasn't on antiretrovirals.\n",
      "\n",
      "Time estimates for each event: The admission is 9/29, discharge 10/4. All events during hospital course need to be placed within that window. The esophagogastroduodenoscopy was on 9/26, which is before admission, so that's part of the history leading to admission. The cultures were sent at admission. The debridement was 10/2, the CT on 10/2? Or maybe the follow-up CT was done after the debridement? Need to check exact text. The text says \"A follow-up CT scan was done which did not show...\" So follow-up from the 1992 one, perhaps during the current stay. The exact date might not be given, but perhaps after the debridement? Alternatively, since the discharge is 10/4, the CT could be done any time on or after admission. The kidney cyst with stone was noted in that follow-up CT.\n",
      "\n",
      "Treatments: Percocet on 10/2 (day 3), ceftriaxone started the same day. Debridement was done that day too. The change to doxycycline was on discharge day (10/4).\n",
      "\n",
      "For each entry, I need to list problem/test/treatment and the date. The HIV diagnosis was in 1991, so the problem includes the HIV status. The weight loss and failure to thrive are ongoing. The abscesses in the legs are acute issues during the current hospitalization.\n",
      "\n",
      "Wait, the current admission's Hospital Course mentions a \"new abscess in her left lower calf and right medial lower extremity quadriceps muscle\". The left calf debridement was on 10/2. The other abscess in the right quad might not have a specific procedure date, but the culture was done at admission.\n",
      "\n",
      "Also, the prior CT in 10/92, so that's before. The esophagogastroduodenoscopy on 9/26, which happened before admission, so that's part of the history leading to admission.\n",
      "\n",
      "The key is to catch all instances of PROBLEM, TEST, TREATMENT with their dates. Let me list them step by step.\n",
      "\n",
      "PROBLEMS:\n",
      "\n",
      "1. Left upper quadrant pain (ongoing, getting worse over past month, first mentioned in the present illness. The pain started at least a year before, as it's happened intermittently for last year. Current during hospital stay?\n",
      "Admission is on 9/29, so the past month's worsening would place the pain starting around late August/early September.\n",
      "\n",
      "2. Nausea and vomiting: same timeline as the pain, ongoing for a while, but worsening.\n",
      "\n",
      "3. HIV infection (diagnosed 1991)\n",
      "\n",
      "4. Abscess in left lower extremity (1991, prior surgery)\n",
      "\n",
      "5. New abscesses in left calf and right quadriceps (present during this admission, as they are 'new' and the reason for admission on 9/29)\n",
      "\n",
      "6. Pancytopenia (due to DDI, leading to not using antiretrovirals)\n",
      "\n",
      "7. Failure to thrive and weight loss (ongoing)\n",
      "\n",
      "TESTS:\n",
      "\n",
      "1. CT scan in 10/1992 (prior)\n",
      "\n",
      "2. Esophagogastroduodenoscopy on 9/26/1993 (prior admission?)\n",
      "\n",
      "3. Cultures sent at admission (09/29/1993, but the text says \"many cultures were sent which were all negative\". They were done upon admission.\n",
      "\n",
      "4. Follow-up CT scan during the current hospital stay (the note says it was done, but the exact date isn't given. Since the debridement was on 10/2, maybe the CT was around then. Alternatively, perhaps the follow-up was after initial tests. Since the follow-up mentions the 1 cm cyst from 1992, perhaps it was done after the debridement. But the text doesn’t specify, so maybe assume during the stay, perhaps on day 3 or later. But to be precise, without an exact date, maybe put as the discharge date? Or just during the hospital stay, as the date isn't specific. However, maybe the follow-up CT was done post-debridement. Alternatively, perhaps the \"follow-up CT\" refers to the same date as the debridement (10/2). Alternatively, the debridement happened on the 2nd, and the CT was done on the 2nd as well. The note says after debridement but not specifically. Hmm. Since the user wants to estimate time, maybe the follow-up CT was done on 10/2 when the debridement occurred. That way they could assess the area post-surgery?\n",
      "\n",
      "Alternatively, the note says \"A follow-up CT scan was done which did not show...\" without a specific date, just part of the hospital course. Maybe it's on the day of discharge, but since discharge is 10/4 and the debridement was 10/2, and they were to be discharged after that. Let's tentatively put it on 10/4 unless there's a better clue. Alternatively, the user might need to estimate as part of the course, but since exact days are mentioned for other tests, maybe it's on the 2nd. Since the prior mention of the 10/2 debridement is on that day. Let's say on 10/2.\n",
      "\n",
      "TREATMENTS:\n",
      "\n",
      "1. Percocet given on the third hospital day (10/2/1993)\n",
      "\n",
      "2. Debridement on 10/2/1993\n",
      "\n",
      "3. IV ceftriaxone started on 10/2/1993 (same day as debridement and Percocet)\n",
      "\n",
      "4. switched to oral doxycycline on discharge day 10/04/1993\n",
      "\n",
      "5. Empirical treatment with ceftriaxone is part of the treatment.\n",
      "\n",
      "Also, prior treatment with DDI that caused pancytopenia, but that was before, so not current.\n",
      "\n",
      "Additionally, the social services connection was part of the admission reason but isn't a treatment per se unless considering social work involvement as a treatment. But probably not a clinical treatment.\n",
      "\n",
      "Another possible entry: the cultures (though cultures are tests, not treatments).\n",
      "\n",
      "Wait, need to categorize each event correctly. Let me make a table.\n",
      "\n",
      "PROBLEM entries:\n",
      "\n",
      "1. Left upper quadrant pain. Onset: intermittently for last year, worsening over past month. Current as of admission 9/29.\n",
      "\n",
      "Date: The problem has been ongoing, but since it's part of why she was admitted, the acute or active phase would be around admission time. But for the sake of the request, perhaps note the date when it was reported. Since it's part of her present illness leading to admission, the timeline is prior to admission but the ongoing nature is part of the problem now.\n",
      "\n",
      "2. Nausea/Vomiting: same as above.\n",
      "\n",
      "3. HIV Positive: diagnosed in 1991.\n",
      "\n",
      "4. New abscesses in left calf and right quadriceps: evident during current admission (starting on admission date 09/29/1993).\n",
      "\n",
      "Also, failure to thrive and weight loss, so maybe 2 separate PROBLEMs (HIV status as problem, and the weight loss as another).\n",
      "\n",
      "TEST:\n",
      "\n",
      "CT in 1992, but that's prior. The current tests during hosp stay are 9/26 endoscopy, but that was done before admission. So when admitted on 29th, the endoscopy was done on 26th, three days prior, but that's part of leading to admission. So maybe that's listed in hospital course? Wait, the hospital course says she was brought in for the EGD on 9/26 but was not sufficiently sedated (maybe the EGD was attempted on 9/26, leading to readmission?), so perhaps she was admitted then readmitted again on 9/29. The exact timeline is a bit tangled. The text says:\n",
      "\n",
      "\"she was brought in for an esophagogastroduodenoscopy on 9/26 but she basically was not sufficiently sedated and readmitted at this time for a GI work-up\".\n",
      "\n",
      "Wait, that wording: \"brought in\" on 9/26 to do the EGD (endoscopy), but she wasn't sedated well enough, so she was \"readmitted at this time\" (now, the current admission starting 9/29). So the readmission refers to the current admission from 9/29 onwards. Thus the EGD was on the 26th, and because of issues, she was readmitted on the 29th. So the EGD's date is 9/26, the prior admission? or just as an outpatient?\n",
      "\n",
      "Assuming the admission on 26th failed, so she was readmitted on the 29th. So the EGD was on the 26th, but not part of this current admission's tests. The current tests during the 29th-10/4 would include cultures sent on 9/29, the CT on 10/2, and follow-up CT after that?\n",
      "\n",
      "TREATMENTS:\n",
      "\n",
      "The Percocet on third day (10/2), the debridement same day, ceftriaxone start on 2nd, then doxy on discharge.\n",
      "\n",
      "Now, to structure each entry with problem/test/treatment, date.\n",
      "\n",
      "PROBLEMS:\n",
      "\n",
      "Left upper quadrant pain with nausea/vomiting (ongoing, worsening over last month, so the timeline is until admission on 29th. The exact start date for the pain is a year ago, but the recent worsening is the past month (so since around mid-August athed so the problem's time would be currently during admission).\n",
      "\n",
      "HIV+ diagnosis in 1991, so that's the 1991 date.\n",
      "\n",
      "The new abscesses as of admission 09/29/1993.\n",
      "\n",
      "Failure to Thrive and weight loss: ongoing, but dates?\n",
      "\n",
      "TESTs:\n",
      "\n",
      "- CT 10/1992 – prior\n",
      "\n",
      "- EGD on 9/26/1993 (though related to current admission, but part of prior attempt)\n",
      "\n",
      "Current during this admission:\n",
      "\n",
      "- Cultures (sent on admission date 09/29)\n",
      "\n",
      "- Follow-up CT (probably 10/2/1993)\n",
      "\n",
      "TREATMENTS:\n",
      "\n",
      "- Percocet (10/2/1993, third day)\n",
      "\n",
      "- debridement (10/2)\n",
      "\n",
      "- ceftriaxone (started on 10/2, discontinued on 10/4 in favor of doxycycline)\n",
      "\n",
      "- doxycycline (on 10/4)\n",
      "\n",
      "Now compiling these into the requested format:\n",
      "\n",
      "Problem entries:\n",
      "\n",
      "1. PROBLEM: Left upper quadrant pain, nausea, and vomiting. Time: Ongoing since at least 1 year ago, with worsening in the past month (prior to admission). Current as of admission 09/29/1993.\n",
      "\n",
      "2. PROBLEM: HIV positivity, diagnosis since 1991.\n",
      "\n",
      "3. PROBLEM: Abscess in left lower extremity (prior: 1991 with resection). Current new abscess in left lower calf and right medial lower extremity (from time of admission on 09/29/1993).\n",
      "\n",
      "4. PROBLEM: Progressive failure to thrive and weight loss, ongoing; dates linked to HIV status and other factors.\n",
      "\n",
      "TEST entries:\n",
      "\n",
      "1. TEST: CT scan abdomen (10/1992) showing liver cyst, non-pancreatic path.\n",
      "\n",
      "2. TEST: Esophagogastroduodenoscopy (EGD) on 9/26/1993 (attempt that led to readmission).\n",
      "\n",
      "3. TEST: Multiple cultures (collected during hospital admission starting on 09/29/1993), all negative.\n",
      "\n",
      "4. TEST: Follow-up CT scan on 10/2/1993 or during hospital stay (specific date assumed as 10/2 based on context with debridement).\n",
      "\n",
      "TREATMENT entries:\n",
      "\n",
      "1. TREATMENT: Percocet administered on 10/2/1993 (third day of hospital stay).\n",
      "\n",
      "2. TREATMENT: Debridement of left calf lesion on 10/2/1993.\n",
      "\n",
      "3. TREATMENT: IV ceftriaxone started on 10/2/1993.\n",
      "\n",
      "4. TREATMENT: Switch to oral doxycycline on 10/4/1993 (discharge day).\n",
      "\n",
      "Others to consider:\n",
      "\n",
      "The DDI (drug) causing pancytopenia – but that's a past treatment, so not current.\n",
      "\n",
      "The failure to thrive is a problem, not a treatment.\n",
      "\n",
      "Maybe categorizing amylase and alkaline phosphatase as tests? The HPI mentions that in 1992, her amylase was mildly elevated; that’s part of the prior data, not during the current admission.\n",
      "\n",
      "Wait, the user might also consider the \"hyperdense kidneys\" or the \"1cm cyst\", but those are findings from the 1992 CT, so not current tests during this stay except the follow-up CT.\n",
      "\n",
      "Also, the abscess cultures from the new sites during this admission would be the cultures sent on 09/29, along with other specimens.\n",
      "\n",
      "So, compiling all into the structured format the user asked for.\n",
      "</think>\n",
      "\n",
      "Here is the extraction of clinical entities (PROBLEM, TEST, TREATMENT) and their estimated timing based on the provided text:\n",
      "\n",
      "---\n",
      "\n",
      "### **PROBLEMs**:\n",
      "1. **Left upper quadrant pain, nausea, and vomiting**  \n",
      "   - **Time**: Ongoing for ≥1 year, with worsening over the past month (prior to admission on 09/29/1993).  \n",
      "   - **Details**: Positional pain worse with exertion, unresponsive to antacids/H2 blockers.  \n",
      "\n",
      "2. **HIV positivity**  \n",
      "   - **Time**: Diagnosed in 1991 during childbirth.  \n",
      "   - **Details**: Heterosexual transmission presumed; no antiretroviral therapy due to pancytopenia and vomiting caused by DDI.  \n",
      "\n",
      "3. **New abscesses in left lower calf and right medial quadriceps muscle**  \n",
      "   - **Time**: Identified at admission on 09/29/1993.  \n",
      "   - **Details**: Require debridement and antibiotic treatment.  \n",
      "\n",
      "4. **Failure to thrive and progressive weight loss**  \n",
      "   - **Time**: Ongoing, with progressive deterioration leading to admission.  \n",
      "   - **Details**: Linked to HIV and ongoing gastrointestinal issues.  \n",
      "\n",
      "---\n",
      "\n",
      "### **TESTs**:\n",
      "1. **CT abdomen (10/1992)**  \n",
      "   - **Time**: Performed in October 1992.  \n",
      "   - **Results**: Fatty liver infiltration, 1 cm liver cyst, hyperdense kidneys, normal pancreas, mildly elevated alkaline phosphatase and transiently elevated amylase.  \n",
      "\n",
      "2. **Esophagogastroduodenoscopy (EGD)**  \n",
      "   - **Time**: Performed on 09/26/1993 (3 days before admission).  \n",
      "   - **Outcome**: Failed due to inadequate sedation, leading to readmission on 09/29/1993.  \n",
      "\n",
      "3. **Culture tests**  \n",
      "   - **Time**: Performed during admission on 09/29/1993 (first day).  \n",
      "   - **Outcome**: Cultures of samples from abscesses were negative.  \n",
      "\n",
      "4. **Follow-up CT abdomen**  \n",
      "   - **Time**: Performed on 10/02/1993 (after debridement of the left calf lesion).  \n",
      "   - **Results**: No splenomegaly/hepatomegaly; previous 1 cm liver cyst unchanged; incidental renal cyst and stones, deemed non-clinically significant.  \n",
      "\n",
      "---\n",
      "\n",
      "### **TREATMENTs**:\n",
      "1. **Percocet administration**  \n",
      "   - **Time**: Initiated on the third hospital day (10/02/1993).  \n",
      "   - **Purpose**: Pain management for left upper quadrant pain.  \n",
      "\n",
      "2. **Debridement of left calf abscess**  \n",
      "   - **Time**: Performed on 10/02/1993.  \n",
      "   - **Details**: Empirical surgical intervention for abscess.  \n",
      "\n",
      "3. **IV ceftriaxone**  \n",
      "   - **Time**: Started on 10/02/1993 (post-debridement).  \n",
      "   - **Purpose**: Empirical treatment for suspected bacterial infection.  \n",
      "\n",
      "4. **Switch to oral doxycycline**  \n",
      "   - **Time**: Discontinued IV ceftriaxone and transitioned to oral doxycycline on discharge (10/04/1993).  \n",
      "   - **Purpose**: Outpatient antibiotic therapy.  \n",
      "\n",
      "---\n",
      "\n",
      "### **Timeline Summary**:\n",
      "- **Admission (09/29/1993)**: Diagnosed with abscesses and re-evaluated for gastrointestinal issues.  \n",
      "- **09/30/1993 (Day 2)**: Cultures obtained, no pain reported.  \n",
      "- **10/01/1993 (Day 3)**: No updates noted in pain until later that day? (Clarify: Pain occurred on Day 3 [10/02], see below).  \n",
      "- **10/02/1993 (Third hospital day)**:  \n",
      "  - Left calf debridement.  \n",
      "  - Percocet started for pain.  \n",
      "  - IV ceftriaxone initiated.  \n",
      "  - Follow-up CT scan.  \n",
      "- **10/04/1993 (Discharge)**: Treated with oral doxycycline.  \n",
      "\n",
      "--- \n",
      "\n",
      "This categorization aligns the extraction with the admission/discharge dates and the text’s timeline. Let me know if further refinements are needed!\n"
     ]
    }
   ],
   "source": [
    "# Define a set of prompts with varying levels of specificity for time extraction\n",
    "prompts = {\n",
    "    \"basic\": \"Extract clinical 'PROBLEM', 'TEST', 'TREATMENT' from the text and estimate the time of each event happened.\",\n",
    "    \"structured\": \"For each clinical event (PROBLEM, TEST, TREATMENT) in the text, provide: 1) The event type, 2) Description, 3) Exact or estimated date/time it occurred, and 4) Your confidence level (high/medium/low).\",\n",
    "    \"temporal_focus\": \"Focus specifically on the temporal information in the text. For each clinical event, determine when it happened relative to other events and to the document creation time. Provide dates when possible, otherwise use relative terms (e.g., '2 days before admission').\",\n",
    "    \"json_format\": \"Extract the temporal information of clinical events as a JSON object. Each event should have: event_type (PROBLEM/TEST/TREATMENT), description, timestamp (exact or estimated), and temporal_indicators (words/phrases that helped you determine the time).\"\n",
    "}\n",
    "\n",
    "def test_temporal_inference(text, prompt_type=\"basic\"):\n",
    "    chat_response = client.chat.completions.create(\n",
    "        model = model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a medical assistant with expertise in understanding clinical timelines and temporal relationships between medical events.\"},\n",
    "            {\"role\": \"user\", \"content\": prompts[prompt_type] + \"\\n\\nCLINICAL TEXT: \" + text},\n",
    "        ]\n",
    "    )\n",
    "    return chat_response.choices[0].message.content\n",
    "\n",
    "# Test the basic extraction\n",
    "if 'text' in locals():\n",
    "    print(\"Testing basic temporal inference:\")\n",
    "    print(test_temporal_inference(text, \"basic\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(src_folder: str):\n",
    "    # Get all .xml.label.txt files in the source folder\n",
    "    label_files = [f for f in os.listdir(src_folder) if f.endswith('.xml.label.txt')]\n",
    "\n",
    "    # Dictionary to store the organized data by file ID\n",
    "    organized_data = {}\n",
    "\n",
    "    # Process each label file\n",
    "    for filename in label_files:\n",
    "        # Extract the file ID (everything before .xml)\n",
    "        file_id = filename.split('.xml')[0]\n",
    "        \n",
    "        # Initialize the dictionary for this ID\n",
    "        organized_data[file_id] = {}\n",
    "\n",
    "        # Load label text file\n",
    "        label_path = os.path.join(src_folder, filename)\n",
    "        with open(label_path, \"r\") as f:\n",
    "            organized_data[file_id]['label_text'] = f.read()\n",
    "\n",
    "        # Load corresponding starttime JSON file\n",
    "        starttime_filename = f\"{file_id}.xml.starttime.json\"\n",
    "        starttime_path = os.path.join(src_folder, starttime_filename)\n",
    "        if os.path.exists(starttime_path):\n",
    "            with open(starttime_path, \"r\") as f:\n",
    "                organized_data[file_id]['starttime'] = json.load(f)\n",
    "        else:\n",
    "            organized_data[file_id]['starttime'] = None\n",
    "\n",
    "        # Load corresponding interval_paths JSON file\n",
    "        interval_paths_filename = f\"{file_id}.xml.interval_paths.json\"\n",
    "        interval_paths_path = os.path.join(src_folder, interval_paths_filename)\n",
    "        if os.path.exists(interval_paths_path):\n",
    "            with open(interval_paths_path, \"r\") as f:\n",
    "                organized_data[file_id]['interval_paths'] = json.load(f)\n",
    "        else:\n",
    "            organized_data[file_id]['interval_paths'] = None\n",
    "\n",
    "    print(f\"Loaded data for {len(organized_data)} IDs.\")\n",
    "    return organized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data for 190 IDs.\n",
      "Loaded data for 120 IDs.\n"
     ]
    }
   ],
   "source": [
    "train_data = data_load('/home/jovyan/work/Temporal_relation/data/timeline_training/')\n",
    "test_data = data_load('/home/jovyan/work/Temporal_relation/data/timeline_test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['751', '201', '98', '373', '332', '701', '512', '92', '42', '237', '546', '722', '307', '807', '532', '87', '471', '433', '388', '626', '346', '272', '336', '11', '193', '271', '316', '502', '777', '567', '417', '472', '291', '2', '122', '413', '572', '582', '331', '313', '393', '72', '321', '23', '636', '167', '786', '481', '362', '382', '591', '423', '736', '81', '166', '707', '422', '47', '38', '301', '492', '511', '656', '6', '51', '631', '647', '717', '186', '622', '787', '711', '411', '126', '267', '177', '216', '121', '1', '482', '367', '212', '473', '387', '188', '682', '308', '191', '521', '18', '721', '173', '797', '576', '637', '462', '641', '386', '357', '273', '318', '692', '577', '168', '68', '163', '541', '43', '757', '213', '203', '343', '311', '497', '337', '426', '348', '28', '252', '776', '463', '197', '153', '26', '596', '396', '376', '3', '496', '522', '557', '408', '491', '242', '756', '151', '236', '123', '427', '747', '152', '432', '366', '36', '458', '517', '172', '791', '681', '452', '801', '182', '351', '107', '612', '16', '438', '697', '666', '611', '602', '642', '116', '248', '218', '86', '141', '143', '93', '437', '162', '156', '352', '178', '676', '302', '468', '8', '407', '571', '256', '587', '96', '547', '356', '192', '353', '526', '247', '726'])"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = train_data['751']['label_text']\n",
    "start_time = train_data['751']['starttime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_temporal_inference(text, events, prompt_type=\"temporal_focus\"):\n",
    "    \"\"\"Evaluate the model's ability to infer time for specific events\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for event in events:\n",
    "        eid = event['node_id']\n",
    "        ground_truth_range = event['start_range']\n",
    "        \n",
    "        # Create a targeted prompt for this specific event\n",
    "        event_prompt = f\"Based on the clinical text, when exactly did the event marked with <{eid}> and </{eid}> occur? \"\n",
    "        event_prompt += \"Provide the most specific date/time possible, whether exact or relative to other events. \"\n",
    "        event_prompt += \"If you're uncertain, explain your level of confidence and the temporal clues you used.\"\n",
    "        \n",
    "        chat_response = client.chat.completions.create(\n",
    "            model = model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a medical assistant with expertise in understanding clinical timelines and temporal relationships between medical events.\"},\n",
    "                {\"role\": \"user\", \"content\": event_prompt + \"\\n\\nCLINICAL TEXT: \" + text},\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        result = {\n",
    "            \"event_id\": eid,\n",
    "            \"ground_truth\": ground_truth_range,\n",
    "            \"llm_inference\": chat_response.choices[0].message.content\n",
    "        }\n",
    "        results.append(result)\n",
    "        \n",
    "        print(f\"\\nEvent ID: {eid}\")\n",
    "        print(f\"Ground truth time range: {ground_truth_range}\")\n",
    "        print(f\"LLM inference: {chat_response.choices[0].message.content}\\n\")\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_prompt_strategies(text, events, prompt_types=[\"basic\", \"structured\", \"temporal_focus\", \"json_format\"]):\n",
    "    \"\"\"Compare different prompting strategies for temporal inference\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Select a representative sample event\n",
    "    if events and len(events) > 0:\n",
    "        sample_event = events[0]\n",
    "        eid = sample_event['node_id']\n",
    "        \n",
    "        print(f\"Comparing prompt strategies for event ID: {eid}\\n\")\n",
    "        \n",
    "        for prompt_type in prompt_types:\n",
    "            print(f\"\\n--- Using {prompt_type} prompt ---\")\n",
    "            \n",
    "            event_text = text.replace(f\"<{eid}>\", f\"**EVENT START**\").replace(f\"</{eid}>\", f\"**EVENT END**\")\n",
    "            \n",
    "            response = test_temporal_inference(event_text, prompt_type)\n",
    "            results[prompt_type] = response\n",
    "            \n",
    "            print(f\"Response:\\n{response}\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'StrOutputParser' from 'langchain.output_parsers' (/opt/conda/lib/python3.11/site-packages/langchain/output_parsers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[489], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SystemMessage, HumanMessage\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StrOutputParser\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_temporal_inference\u001b[39m(text, events):\n\u001b[1;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate the model's ability to infer time for specific events\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'StrOutputParser' from 'langchain.output_parsers' (/opt/conda/lib/python3.11/site-packages/langchain/output_parsers/__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.llms import VLLMOpenAI\n",
    "\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from langchain.output_parsers import StrOutputParser\n",
    "\n",
    "def evaluate_temporal_inference(text, events):\n",
    "    \"\"\"Evaluate the model's ability to infer time for specific events\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Define system message once\n",
    "    system_message = \"You are a medical assistant with expertise in understanding clinical timelines and temporal relationships between medical events.\"\n",
    "    \n",
    "    for event in events:\n",
    "        eid = event['node_id']\n",
    "        ground_truth_range = event['start_range']\n",
    "        \n",
    "        # Create user message with clinical text\n",
    "        event_prompt = f\"Based on the clinical text, when exactly did the event marked with <{eid}> and </{eid}> occur? \"\n",
    "        event_prompt += \"Provide the most specific date/time possible, whether exact or relative to other events. \"\n",
    "        event_prompt += \"If you're uncertain, explain your level of confidence and the temporal clues you used.\"\n",
    "        user_content = f\"{event_prompt}\\n\\nCLINICAL TEXT: {text}\"\n",
    "        \n",
    "        # Define messages in chat format\n",
    "        messages = [\n",
    "            SystemMessage(content=system_message),\n",
    "            HumanMessage(content=user_content)\n",
    "        ]\n",
    "        \n",
    "        # Create proper chat prompt template\n",
    "        chat_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "        \n",
    "        # Create chain with chat format\n",
    "        chain = chat_prompt | llm | StrOutputParser()\n",
    "        \n",
    "        # Get response\n",
    "        langchain_response = chain.invoke({})\n",
    "        print(f\"Langchain LLM inference: {langchain_response}\\n\")\n",
    "        \n",
    "        # Also get raw client response for comparison\n",
    "        chat_response = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_content},\n",
    "            ]\n",
    "        )\n",
    "        raw_response = chat_response.choices[0].message.content\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            \"event_id\": eid,\n",
    "            \"ground_truth\": ground_truth_range,\n",
    "            \"langchain_inference\": langchain_response,\n",
    "            \"raw_inference\": raw_response\n",
    "        }\n",
    "        results.append(result)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\nEvent ID: {eid}\")\n",
    "        print(f\"Ground truth time range: {ground_truth_range}\")\n",
    "        print(f\"Langchain inference: {langchain_response}\")\n",
    "        print(f\"Raw client inference: {raw_response}\\n\")\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "model_name = 'Qwen/QwQ-32B-AWQ'\n",
    "# Earlier in your code, modify the llm initialization\n",
    "llm = VLLMOpenAI(\n",
    "    openai_api_key=openai_api_key,\n",
    "    openai_api_base=openai_api_base,\n",
    "    model_name=model_name,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "def evaluate_temporal_inference(text, events):\n",
    "    \"\"\"Evaluate the model's ability to infer time for specific events\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Define system message just once (same as in your raw implementation)\n",
    "    system_message = \"You are a medical assistant with expertise in understanding clinical timelines and temporal relationships between medical events.\"\n",
    "    \n",
    "    for event in events:\n",
    "        eid = event['node_id']\n",
    "        ground_truth_range = event['start_range']\n",
    "        \n",
    "        # Create a targeted prompt for this specific event\n",
    "        event_prompt = f\"Based on the clinical text, when exactly did the event marked with <{eid}> and </{eid}> occur? \"\n",
    "        event_prompt += \"Provide the most specific date/time possible, whether exact or relative to other events. \"\n",
    "        event_prompt += \"If you're uncertain, explain your level of confidence and the temporal clues you used.\"\n",
    "        \n",
    "        user_content = f\"{event_prompt}\\n\\nCLINICAL TEXT: {text}\"\n",
    "        \n",
    "        # Create a chat prompt template with system and user messages\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessage(content=system_message),\n",
    "            HumanMessage(content=user_content)\n",
    "        ])\n",
    "        \n",
    "        # Build the chain with the prompt template\n",
    "        chain = chat_prompt | llm | StrOutputParser()\n",
    "        \n",
    "        # Get langchain response\n",
    "        langchain_response = chain.invoke({})\n",
    "        print(f\"Langchain LLM inference: {langchain_response}\\n\")\n",
    "        print(\"*\" * 80)\n",
    "\n",
    "        # Also get raw client response for comparison\n",
    "        chat_response = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_content},\n",
    "            ]\n",
    "        )\n",
    "        raw_response = chat_response.choices[0].message.content\n",
    "\n",
    "        result = {\n",
    "            \"event_id\": eid,\n",
    "            \"ground_truth\": ground_truth_range,\n",
    "            \"langchain_inference\": langchain_response,\n",
    "            \"raw_inference\": raw_response\n",
    "        }\n",
    "        results.append(result)\n",
    "        \n",
    "        print(f\"\\nEvent ID: {eid}\")\n",
    "        print(f\"Ground truth time range: {ground_truth_range}\")\n",
    "        print(f\"Langchain inference: {langchain_response}\")\n",
    "        print(f\"Raw client inference: {raw_response}\\n\")\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_temporal_inference(text, start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, event_id):\n",
    "    \"\"\"\n",
    "    Removes all event tags <E#> and </E#> from the text, except for the specified event tag.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text containing event tags\n",
    "        event_id (str): The event ID to keep (e.g., \"E2\", \"E5\", etc.)\n",
    "        \n",
    "    Returns:\n",
    "        str: The text with all event tags removed except for the specified event\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Strip the 'E' prefix if it exists to get just the number\n",
    "    if event_id.startswith('E'):\n",
    "        event_num = event_id[1:]\n",
    "    else:\n",
    "        event_num = event_id\n",
    "        event_id = 'E' + event_id\n",
    "    \n",
    "    # Create the pattern to match all <E#> and </E#> tags except the specified one\n",
    "    pattern = r'<E(?!{0}>)(\\d+)>|</E(?!{0}>)(\\d+)>'.format(event_num)\n",
    "    \n",
    "    # Remove all matches of the pattern\n",
    "    processed_text = re.sub(pattern, '', text)\n",
    "    \n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The patient is a 28-year-old woman who is <E2>HIV positive</E2> for two years. She presented with left upper quadrant pain as well as nausea and vomiting.\n"
     ]
    }
   ],
   "source": [
    "# This will keep <E5> and </E5> tags and remove all others\n",
    "text = \"The patient is a 28-year-old woman who is <E2>HIV positive</E2> for two years. \" \\\n",
    "       \"She presented with <E4>left upper quadrant pain</E4> as well as <E5>nausea</E5> and <E6>vomiting</E6>.\"\n",
    "       \n",
    "processed_text = preprocess_text(text, \"E2\")\n",
    "print(processed_text)\n",
    "# Output: \"The patient is a 28-year-old woman who is HIV positive for two years. \" \\\n",
    "#        \"She presented with left upper quadrant pain as well as <E5>nausea</E5> and vomiting.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 =['316', '197', '468', '163', '682', '18', '272', '521', '201', '511', '8', '411', '386', '582', '462', '152', '757', '236', '357', '237', '122', '23', '458', '311', '313', '26', '3', '167', '577', '11', '166', '173', '497', '526', '321', '502', '216', '93', '203', '393', '591', '367', '491', '482', '676', '636', '51', '331', '567', '182']\n",
    "list2 = ['751', '201', '98', '373', '332', '701', '512', '92', '42', '237', '546', '722', '307', '807', '532', '87', '471', '433', '388', '626', '346', '272', '336', '11', '193', '271', '316', '502', '777', '567', '417', '472', '291', '2', '122', '413', '572', '582', '331', '313', '393', '72', '321', '23', '636', '167', '786', '481', '362', '382']\n",
    "list3 = ['316', '197', '468', '163', '682', '18', '272', '521', '201', '511', '8', '411', '386', '582', '462', '152', '757', '236', '357', '237', '122', '23', '458', '311', '313', '26', '3', '167', '577', '11', '166', '173', '497', '526', '321', '502', '216', '93', '203', '393', '591', '367', '491', '482', '676', '636', '51']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list1) == set(list2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list3) == set(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list1) == set(list3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['1.xml.notime.label.txt', '107.xml.notime.label.txt', '11.xml.notime.label.txt', '116.xml.notime.label.txt', '121.xml.notime.label.txt', '122.xml.notime.label.txt', '123.xml.notime.label.txt', '126.xml.notime.label.txt', '141.xml.notime.label.txt', '143.xml.notime.label.txt', '151.xml.notime.label.txt', '152.xml.notime.label.txt', '153.xml.notime.label.txt', '156.xml.notime.label.txt', '16.xml.notime.label.txt', '162.xml.notime.label.txt', '163.xml.notime.label.txt', '166.xml.notime.label.txt', '167.xml.notime.label.txt', '168.xml.notime.label.txt', '172.xml.notime.label.txt', '173.xml.notime.label.txt', '177.xml.notime.label.txt', '178.xml.notime.label.txt', '18.xml.notime.label.txt', '182.xml.notime.label.txt', '186.xml.notime.label.txt', '188.xml.notime.label.txt', '191.xml.notime.label.txt', '192.xml.notime.label.txt', '193.xml.notime.label.txt', '197.xml.notime.label.txt', '2.xml.notime.label.txt', '201.xml.notime.label.txt', '203.xml.notime.label.txt', '212.xml.notime.label.txt', '213.xml.notime.label.txt', '216.xml.notime.label.txt', '218.xml.notime.label.txt', '23.xml.notime.label.txt', '236.xml.notime.label.txt', '237.xml.notime.label.txt', '242.xml.notime.label.txt', '247.xml.notime.label.txt', '248.xml.notime.label.txt', '252.xml.notime.label.txt', '256.xml.notime.label.txt', '26.xml.notime.label.txt', '267.xml.notime.label.txt', '271.xml.notime.label.txt', '272.xml.notime.label.txt', '273.xml.notime.label.txt', '28.xml.notime.label.txt', '291.xml.notime.label.txt', '3.xml.notime.label.txt', '301.xml.notime.label.txt', '302.xml.notime.label.txt', '307.xml.notime.label.txt', '308.xml.notime.label.txt', '311.xml.notime.label.txt', '313.xml.notime.label.txt', '316.xml.notime.label.txt', '318.xml.notime.label.txt', '321.xml.notime.label.txt', '331.xml.notime.label.txt', '332.xml.notime.label.txt', '336.xml.notime.label.txt', '337.xml.notime.label.txt', '343.xml.notime.label.txt', '346.xml.notime.label.txt', '348.xml.notime.label.txt', '351.xml.notime.label.txt', '352.xml.notime.label.txt', '353.xml.notime.label.txt', '356.xml.notime.label.txt', '357.xml.notime.label.txt', '36.xml.notime.label.txt', '362.xml.notime.label.txt', '366.xml.notime.label.txt', '367.xml.notime.label.txt', '373.xml.notime.label.txt', '376.xml.notime.label.txt', '38.xml.notime.label.txt', '382.xml.notime.label.txt', '386.xml.notime.label.txt', '387.xml.notime.label.txt', '388.xml.notime.label.txt', '393.xml.notime.label.txt', '396.xml.notime.label.txt', '407.xml.notime.label.txt', '408.xml.notime.label.txt', '411.xml.notime.label.txt', '413.xml.notime.label.txt', '417.xml.notime.label.txt', '42.xml.notime.label.txt', '422.xml.notime.label.txt', '423.xml.notime.label.txt', '426.xml.notime.label.txt', '427.xml.notime.label.txt', '43.xml.notime.label.txt', '432.xml.notime.label.txt', '433.xml.notime.label.txt', '437.xml.notime.label.txt', '438.xml.notime.label.txt', '452.xml.notime.label.txt', '458.xml.notime.label.txt', '462.xml.notime.label.txt', '463.xml.notime.label.txt', '468.xml.notime.label.txt', '47.xml.notime.label.txt', '471.xml.notime.label.txt', '472.xml.notime.label.txt', '473.xml.notime.label.txt', '481.xml.notime.label.txt', '482.xml.notime.label.txt', '491.xml.notime.label.txt', '492.xml.notime.label.txt', '496.xml.notime.label.txt', '497.xml.notime.label.txt', '502.xml.notime.label.txt', '51.xml.notime.label.txt', '511.xml.notime.label.txt', '512.xml.notime.label.txt', '517.xml.notime.label.txt', '521.xml.notime.label.txt', '522.xml.notime.label.txt', '526.xml.notime.label.txt', '532.xml.notime.label.txt', '541.xml.notime.label.txt', '546.xml.notime.label.txt', '547.xml.notime.label.txt', '557.xml.notime.label.txt', '567.xml.notime.label.txt', '571.xml.notime.label.txt', '572.xml.notime.label.txt', '576.xml.notime.label.txt', '577.xml.notime.label.txt', '582.xml.notime.label.txt', '587.xml.notime.label.txt', '591.xml.notime.label.txt', '596.xml.notime.label.txt', '6.xml.notime.label.txt', '602.xml.notime.label.txt', '611.xml.notime.label.txt', '612.xml.notime.label.txt', '622.xml.notime.label.txt', '626.xml.notime.label.txt', '631.xml.notime.label.txt', '636.xml.notime.label.txt', '637.xml.notime.label.txt', '641.xml.notime.label.txt', '642.xml.notime.label.txt', '647.xml.notime.label.txt', '656.xml.notime.label.txt', '666.xml.notime.label.txt', '676.xml.notime.label.txt', '68.xml.notime.label.txt', '681.xml.notime.label.txt', '682.xml.notime.label.txt', '692.xml.notime.label.txt', '697.xml.notime.label.txt', '701.xml.notime.label.txt', '707.xml.notime.label.txt', '711.xml.notime.label.txt', '717.xml.notime.label.txt', '72.xml.notime.label.txt', '721.xml.notime.label.txt', '722.xml.notime.label.txt', '726.xml.notime.label.txt', '736.xml.notime.label.txt', '747.xml.notime.label.txt', '751.xml.notime.label.txt', '756.xml.notime.label.txt', '757.xml.notime.label.txt', '776.xml.notime.label.txt', '777.xml.notime.label.txt', '786.xml.notime.label.txt', '787.xml.notime.label.txt', '791.xml.notime.label.txt', '797.xml.notime.label.txt', '8.xml.notime.label.txt', '801.xml.notime.label.txt', '807.xml.notime.label.txt', '81.xml.notime.label.txt', '86.xml.notime.label.txt', '87.xml.notime.label.txt', '92.xml.notime.label.txt', '93.xml.notime.label.txt', '96.xml.notime.label.txt', '98.xml.notime.label.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['1.xml.label.txt', '107.xml.label.txt', '11.xml.label.txt', '116.xml.label.txt', '121.xml.label.txt', '122.xml.label.txt', '123.xml.label.txt', '126.xml.label.txt', '141.xml.label.txt', '143.xml.label.txt', '151.xml.label.txt', '152.xml.label.txt', '153.xml.label.txt', '156.xml.label.txt', '16.xml.label.txt', '162.xml.label.txt', '163.xml.label.txt', '166.xml.label.txt', '167.xml.label.txt', '168.xml.label.txt', '172.xml.label.txt', '173.xml.label.txt', '177.xml.label.txt', '178.xml.label.txt', '18.xml.label.txt', '182.xml.label.txt', '186.xml.label.txt', '188.xml.label.txt', '191.xml.label.txt', '192.xml.label.txt', '193.xml.label.txt', '197.xml.label.txt', '2.xml.label.txt', '201.xml.label.txt', '203.xml.label.txt', '212.xml.label.txt', '213.xml.label.txt', '216.xml.label.txt', '218.xml.label.txt', '23.xml.label.txt', '236.xml.label.txt', '237.xml.label.txt', '242.xml.label.txt', '247.xml.label.txt', '248.xml.label.txt', '252.xml.label.txt', '256.xml.label.txt', '26.xml.label.txt', '267.xml.label.txt', '271.xml.label.txt', '272.xml.label.txt', '273.xml.label.txt', '28.xml.label.txt', '291.xml.label.txt', '3.xml.label.txt', '301.xml.label.txt', '302.xml.label.txt', '307.xml.label.txt', '308.xml.label.txt', '311.xml.label.txt', '313.xml.label.txt', '316.xml.label.txt', '318.xml.label.txt', '321.xml.label.txt', '331.xml.label.txt', '332.xml.label.txt', '336.xml.label.txt', '337.xml.label.txt', '343.xml.label.txt', '346.xml.label.txt', '348.xml.label.txt', '351.xml.label.txt', '352.xml.label.txt', '353.xml.label.txt', '356.xml.label.txt', '357.xml.label.txt', '36.xml.label.txt', '362.xml.label.txt', '366.xml.label.txt', '367.xml.label.txt', '373.xml.label.txt', '376.xml.label.txt', '38.xml.label.txt', '382.xml.label.txt', '386.xml.label.txt', '387.xml.label.txt', '388.xml.label.txt', '393.xml.label.txt', '396.xml.label.txt', '407.xml.label.txt', '408.xml.label.txt', '411.xml.label.txt', '413.xml.label.txt', '417.xml.label.txt', '42.xml.label.txt', '422.xml.label.txt', '423.xml.label.txt', '426.xml.label.txt', '427.xml.label.txt', '43.xml.label.txt', '432.xml.label.txt', '433.xml.label.txt', '437.xml.label.txt', '438.xml.label.txt', '452.xml.label.txt', '458.xml.label.txt', '462.xml.label.txt', '463.xml.label.txt', '468.xml.label.txt', '47.xml.label.txt', '471.xml.label.txt', '472.xml.label.txt', '473.xml.label.txt', '481.xml.label.txt', '482.xml.label.txt', '491.xml.label.txt', '492.xml.label.txt', '496.xml.label.txt', '497.xml.label.txt', '502.xml.label.txt', '51.xml.label.txt', '511.xml.label.txt', '512.xml.label.txt', '517.xml.label.txt', '521.xml.label.txt', '522.xml.label.txt', '526.xml.label.txt', '532.xml.label.txt', '541.xml.label.txt', '546.xml.label.txt', '547.xml.label.txt', '557.xml.label.txt', '567.xml.label.txt', '571.xml.label.txt', '572.xml.label.txt', '576.xml.label.txt', '577.xml.label.txt', '582.xml.label.txt', '587.xml.label.txt', '591.xml.label.txt', '596.xml.label.txt', '6.xml.label.txt', '602.xml.label.txt', '611.xml.label.txt', '612.xml.label.txt', '622.xml.label.txt', '626.xml.label.txt', '631.xml.label.txt', '636.xml.label.txt', '637.xml.label.txt', '641.xml.label.txt', '642.xml.label.txt', '647.xml.label.txt', '656.xml.label.txt', '666.xml.label.txt', '676.xml.label.txt', '68.xml.label.txt', '681.xml.label.txt', '682.xml.label.txt', '692.xml.label.txt', '697.xml.label.txt', '701.xml.label.txt', '707.xml.label.txt', '711.xml.label.txt', '717.xml.label.txt', '72.xml.label.txt', '721.xml.label.txt', '722.xml.label.txt', '726.xml.label.txt', '736.xml.label.txt', '747.xml.label.txt', '751.xml.label.txt', '756.xml.label.txt', '757.xml.label.txt', '776.xml.label.txt', '777.xml.label.txt', '786.xml.label.txt', '787.xml.label.txt', '791.xml.label.txt', '797.xml.label.txt', '8.xml.label.txt', '801.xml.label.txt', '807.xml.label.txt', '81.xml.label.txt', '86.xml.label.txt', '87.xml.label.txt', '92.xml.label.txt', '93.xml.label.txt', '96.xml.label.txt', '98.xml.label.txt']\n",
    "\n",
    "# ['1', '107', '11', '116', '121', '122', '123', '126', '141', '143']\n",
    "# ['1', '107', '11', '116', '121', '122', '123', '126', '141', '143']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
